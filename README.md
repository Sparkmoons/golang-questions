# Golang Interview Questions :rocket:

Добро пожаловать в репозиторий с вопросами по Golang для подготовки к интервью. Здесь вы найдете вопросы, которые могут быть заданы на интервью, с подробными разъяснениями и анализом различных corner cases. Представьте, что это ваши билеты на экзамен - вытягивайте билет и готовьтесь!

Подготовка :muscle:
Перед началом подготовки рекомендуем вам создать тихую рабочую обстановку без отвлекающих факторов.
Не пугайтесь, если не можете ответить на вопрос сразу. Главное - это процесс обучения и понимания.
Не забудьте также ознакомиться с базовыми понятиями Golang: slices, maps, structs и другие.

## Оглавление :book:

1. [Slices](#slices)
1. [Указатели](#указатели)
1. [Goroutines и Channels](#goroutines-и-channels)
1. [Работа со строками](#работа-со-строками)

---

## Slices

### Вопрос 1: Почему следующий код может вызвать проблемы и как его можно улучшить??

Что будет в s1 после выполнения этого кода и почему?

```go
s1 := []int{1, 2, 3}
s2 := s1[:2]
s2[0] = 9
```

<details>
  <summary>Ответ</summary>
s1 и s2 ссылаются на один и тот же массив данных, проблема может быть вызвана тем что при изменении элементов во втором слайсе (s2) элемент поменяется и в слайсе #1. Такое поведение возможно до тех пор пока, например, не произойдет переаллокация памяти в случае превышения `cap` например в слайсе #1, тем самым слайс #1 будет ссылаться уже на другой массив, отличный от второго.
</details>

### Вопрос 2: Почему, когда вы добавляете элемент в слайс с помощью `append`, иногда вам может понадобиться новый участок памяти, и иногда — нет?

Как это связано с емкостью (capacity) слайса?

<details>
  <summary>Ответ</summary>
Слайс представляет собой структуру, в которой есть `len`, `cap` и указатель на массив данных. 
`Len` - это количество элементов в данном массиве, а `Cap` - максимальная емкость, при превышении которой в случае append (например) происходит переаллокация памяти (обычно в два раза больше текущего) для нового массива в котором будет достаточно места для добавляемых элементов.
Данная операция является затратной, так как происходит копирование всех элементов из одного массива в новый.
</details>

### Вопрос 3: Nil vs Empty slice: Какова разница между nil слайсом и пустым слайсом? В каких случаях один из них предпочтительнее другого?

<details>
  <summary>Ответ</summary>
`Nil` слайс и пустой слайс – это разные вещи. `Nil` слайс не имеет выделенной памяти и его длина и емкость равны нулю. Но это не значит, что вы не можете добавить в него элементы с помощью append.
Пустой слайс, с другой стороны, уже может иметь выделенную память (например, после создания с помощью make([]T, 0)), но его текущая длина равна нулю.
</details>

### Вопрос 4: Как бы вы удалили элемент из слайса без использования стандартной библиотеки, не нарушив порядок следования элементов?

<details>
  <summary>Ответ</summary>
В случае если элемент, который необходимо удалить находится в начале или конце это можно сделать с помощью среза,
например - 
> [!NOTE]
> new_slice[index_of_element_to delete+1 :]
> new_slice[ :index_of_element_to delete]

или если в середине -

> [!NOTE]
> append(slice[:s], slice[s+1:]...)

</details>

### Вопрос 5: Можно ли утверждать, что после обрезания большого слайса до меньшего (например, largeSlice = largeSlice[:5]) память, занимаемая оставшимися элементами, будет освобождена?

Если нет, почему и как это может привести к утечке памяти?

<details>
  <summary>Ответ</summary>
Память освобождена не будет так как в Golang `cap` для нового слайса расчитывается из формулы:

> [!NOTE]
> cap(new_slice) = cap(original_slice)−start_index_of_new_slice

Таким образом новый слайс будет ссылаться на тот же массив что и старый, до тех пор пока не произойдет реаалокация памяти в случае превышения cap текущего слайса. Только после реалокации памяти и переноса значений в новый слайс, garbage collector очистит память старого массива если на него не будут указывать другие слайсы.
Если у вас есть большой слайс, и вы создаете из него маленький срез, это может привести к неожиданному удержанию памяти. Если вы знаете, что оригинальный большой слайс больше не нужен, и вы хотите избежать утечек памяти, можете явно скопировать данные в новый слайс с помощью `copy`.

</details>

## Указатели

### Вопрос 1: Что выведет следующий код?

```go
func setLinkHome(link *string) {
    *link = "http://home"
}

link := "http://other"
setLinkHome(&link)
fmt.Println(link)
```

<details>
  <summary>Ответ</summary>
Код выведет: `"http://home"`
Почему: Функция `setLinkHome` принимает указатель на строку и устанавливает значение этой строки как `"http://home"`. Поэтому значение переменной `link` будет изменено на `"http://home"`.
На первый взгляд достаточно просто, но давайте разберемся почему так происходит, ведь строки являются не изменяемыми типами данных в Golang
`link := "http://other"` - Вы создаете переменную `link` и присваиваете ей значение "http://other".

Представим как это будет выглдяеть на стеке:
`link -> адрес в куче #1`

В куче:
`адрес #1: "http://other"`

Вы вызываете setLinkHome(&link), передавая адрес переменной link в функцию.
Внутри `setLinkHome`, вы присваиваете новое значение по этому адресу: `*link = "http://home"`.

Теперь память выглядит следующим образом:
На стеке:
link -> адрес в куче #2

В куче:
адрес #1: "http://other" (больше не используется)
адрес #2: "http://home"

Значение по адресу #1 ("http://other") теперь не имеет ссылок на него, поэтому оно может быть освобождено сборщиком мусора в будущем.

    Когда вы вызываете fmt.Println(link), выведется "http://home", так как переменная link теперь указывает на новую строку в куче.

Итак, ваш код действительно выведет "http://home".

Отмечу, что с точки зрения реализации Go, строки часто хранятся в неизменяемых массивах байтов, и когда вы "изменяете" строку, вы на самом деле создаете новую строку, указывающую на другой участок этого массива или на другой массив. Но для большинства случаев можно думать о строках как о данных в куче, на которые ссылаются переменные на стеке.

</details>

### Вопрос 2: Будет ли напечатан `ok`?

```go
func main() {
    defer func() {
        recover()
    }()
    panic("test panic")
    fmt.Println("ok")
}
```

<details>
  <summary>Ответ</summary>
Нет, `"ok"` не будет напечатано.
Почему: Функция `panic` прекращает выполнение текущей функции и начинает распространять панику по стеку вызовов. Однако благодаря `defer` и `recover()` программа не завершится аварийно, но после panic `"ok"` уже не будет выполнено.</details>
</details>

### Вопрос 3: Исправь код, функция должна выводить:

```
// one
// two
// three
// (в любом порядке и в конце обязательно)
// Done!
// Исправь код
```

```go
func printText(data []string) {
    wg := sync.WaitGroup{}
    for _, v := range data {
        go func(v string ) {
            wg.Add(1)
            fmt.Println(v)
            wg.Done()
        }()
    }
    fmt.Println("done!")
}

data := []string{"one", "two", "three"}
printText(data)
```

<details>
  <summary>Ответ</summary>
Проблема заключается в том, что функция `wg.Add(1)` вызывается внутри горутины, что может привести к непредсказуемым результатам.
Исправленный код:
```go
func printText(data []string) {
    wg := sync.WaitGroup{}
    for _, v := range data {
        wg.Add(1)
        go func(v string ) {
            defer wg.Done()
            fmt.Println(v)
        }(v)
    }
    wg.Wait()
    fmt.Println("Done!")
}
```
</details>

### Вопрос 4: Мы пытаемся подсчитать количество выполненных параллельно операций, что может пойти не так?

```go
var callCounter uint

func main() {
    for i := 0; i < 10000; i++ {
        go func() {
            // Ходим в базу, делаем долгую работу
            time.Sleep(time.Second)
            // Увеличиваем счетчик
            callCounter++
        }()
    }
    fmt.Println("Call counter value = ", callCounter)
}
```

<details>
  <summary>Ответ</summary>
Проблема в том, что доступ к `callCounter` не синхронизирован, что может привести к состоянию гонки и неправильным результатам.
Почему: Несколько горутин могут попытаться увеличить значение `callCounter` одновременно.
</details>

### Вопрос 5: Есть функция processDataInternal, которая может выполняться неопределенно долго. Чтобы контролировать процесс, мы добавили таймаут выполнения ф-ии через context. Какие недостатки кода ниже?

```go
func (s *Service) ProcessData(timeoutCtx context.Context, r io.Reader) error {
  errCh := make(chan error)

  go func() {
    errCh <- s.processDataInternal(r)
  }()


  select {
  case err := <-errCh:
    return err
  case <-timeoutCtx.Done():
    return timeoutCtx.Err()
  }
}
```

<details>
  <summary>Ответ</summary>
1. Если `processDataInternal` превышает установленный тайм-аут, горутина будет продолжать работать в фоне даже после того, как `ProcessData` вернет ошибку тайм-аута.
2. Канал `errCh` не закрывается, что может привести к утечкам памяти.
3. Нет способа передать информацию в `processDataInternal`, что ему нужно остановиться из-за тайм-аута по контексту.

Учитывая все вышеперечисленные моменты, следует

1. Использовать канал с ограниченной емкостью.
2. Закрыть канал `errrCh`
3. Передать `timeoutCtx` в `processDataInternal`, чтобы можно было отслеживать состояние тайм-аута и прерывать выполнение при необходимости.

Исправленный код:

```go
func (s *Service) ProcessData(timeoutCtx context.Context, r io.Reader) error {
    // Создаем канал с емкостью 1, чтобы избежать блокировки при отправке данных
    errCh := make(chan error, 1)

    go func() {
        defer close(errCh) // Гарантируем закрытие канала при завершении горутины
        errCh <- s.processDataInternal(timeoutCtx, r)
    }()

    select {
    case err := <-errCh:
        return err
    case <-timeoutCtx.Done():
        return timeoutCtx.Err()
    }
}

// Обновляем processDataInternal, чтобы принимать context.Context
// и проверять его состояние при выполнении долгой операции
func (s *Service) processDataInternal(ctx context.Context, r io.Reader) error {
    // TODO: Ваша реализация. Включите проверки ctx.Done() в долгих операциях,
    // чтобы прервать выполнение при тайм-ауте.
    return nil
}
```

Эти изменения гарантируют, что:

    Канал будет закрыт, исключая утечку памяти.
    Если `processDataInternal` поддерживает отслеживание состояния context, можно завершить операцию при достижении тайм-аута.

Однако следует учесть, что завершение `processDataInternal` при тайм-ауте зависит от того, как реализована функция и проверяется ли состояние контекста внутри нее. Если долгая операция не поддерживает прерывание, то она будет продолжать работать в фоне до своего завершения.

Использование каналов с ограниченной емкостью (буферизованных каналов) в Go может быть полезным в определенных ситуациях.
Вот примеры, которые могут помочь понять, почему и когда это может быть полезно:

1.  Избежание блокировки горутины:
    Представьте ситуацию, где горутина пытается отправить сообщение в канал, но нет другой горутины, готовой принять это сообщение. Если канал не буферизован, отправляющая горутина заблокируется. С буферизованным каналом, горутина не будет заблокирована, пока есть свободное место в буфере.

    Пример: У вас есть система, которая отправляет логи через канал. Если обработчик логов временно занят и не может принять новые сообщения, буферизованный канал позволит продолжать добавлять логи в буфер, предотвращая блокировку отправляющих горутин.

2.  Производительность:
    Буферизованные каналы часто могут улучшить производительность, так как отправка и получение сообщений не требует немедленной синхронизации между горутинами.

    Пример: Представьте себе конвейер в заводе. Если каждый рабочий (горутина) должен будет ждать следующего рабочего перед передачей детали, это будет медленным. Но если у них есть промежуточные корзины (буферы), они могут продолжать работать, пока корзина не заполнится.

3.  Ограничение ресурсов:
    Буферизованные каналы позволяют ограничивать количество обрабатываемых данных, что может быть полезно, чтобы избежать излишнего потребления памяти или других ресурсов.

    Пример: У вас есть сервис, который загружает изображения. Пользователи могут запросить загрузку сотен изображений одновременно. Буферизованный канал позволяет ограничивать количество одновременно обрабатываемых изображений, предотвращая перегрузку системы.

Тем не менее, важно отметить, что неправильное использование буферизованных каналов также может привести к проблемам, таким как утечки памяти (если вы постоянно добавляете в канал, но никогда не читаете из него). Всегда стоит тщательно анализировать и тестировать код, чтобы обеспечить правильное и эффективное использование каналов.

Если все еще непонятно, почему мы используем буферизированный канал, читайте дальше:

1. Длительная блокировка может привести к таймаутам: Если у вас есть внешний сервис или клиент, который ожидает ответа от вашего приложения, длительная блокировка может привести к превышению времени ожидания.

Пример: Вы разрабатываете веб-сервер, который принимает запросы на обработку данных. Каждый запрос инициирует горутину, которая пытается отправить данные на обработку через канал. Если обработчик временно занят, горутина будет заблокирована, и клиент может столкнуться с таймаутом.

2. Неэффективное использование ресурсов: Горутины, заблокированные из-за попытки отправки в канал, продолжают занимать системные ресурсы, даже если они не выполняют полезной работы.

Пример: Ваше приложение начинает тысячи горутин для обработки задач. Если все они блокируются из-за канала, это может привести к значительному потреблению памяти и ресурсов CPU.

3. Опасность взаимной блокировки: Если и отправляющая, и принимающая горутины ожидают друг друга, это может привести к взаимной блокировке, и ваше приложение может "зависнуть".

Пример: Горутина A ожидает, пока горутина B прочитает из канала, чтобы продолжить работу. Одновременно горутина B ожидает, пока горутина A что-то сделает, прежде чем читать из канала. Обе горутины блокируются навсегда.

4. Опеределение поведения приложения: В некоторых случаях блокировка может быть желаемым поведением, чтобы контролировать скорость обработки или для синхронизации задач.

РЕАЛЬНЫЙ ПРИМЕР:
Давайте представим завод, на котором есть конвейерная лента для производства игрушек. Этот конвейер разделен на два этапа:

    Этап А: Машина, которая делает детали для игрушек.
    Этап В: Работник, который собирает игрушку из этих деталей.

Между этими этапами у нас есть корзина, в которую машина (Этап А) кладет детали, и из которой работник (Этап В) берет детали для сборки игрушки.

Взаимная блокировка на примере завода:

Представьте, что машина на Этапе А может работать только тогда, когда в корзине нет деталей. Она ждет, пока работник на Этапе В не заберет все детали из корзины. С другой стороны, работник на Этапе В может начать сборку только после того, как в корзине накопится определенное количество деталей.

Взаимная блокировка произойдет в ситуации, когда в корзине будет недостаточно деталей для работника на Этапе В, чтобы начать сборку, но и достаточно деталей, чтобы машина на Этапе А не могла продолжить свою работу. Оба этапа будут ждать друг друга, и производство остановится.

Таким образом, если система (или код) не предусматривает механизма разрешения такой блокировки или предотвращения ее возникновения, это может привести к тому, что весь процесс "зависнет".

</details>

### Вопрос 6: Что выведет программа?

```go
func a() {
    x := []int{}
    x = append(x, 0)
    x = append(x, 1)
    x = append(x, 2)
    y := append(x, 3)
    z := append(x, 4)
    fmt.Println(y, z)
}

func main() {
    a()
}
```

<details>
  <summary>Ответ</summary>
func a() {
    x := []int{}
    x = append(x, 0) // длина = 1, емкость = 2
    x = append(x, 1) // длина = 2, емкость = 2 
    x = append(x, 2) // длина = 3, емкость = 4
    y := append(x, 3) // длина = 4, емкость = 4
    z := append(x, 4) // длина = 4, емкость = 4
    fmt.Println(y, z) // [0, 1, 2, 3] [0, 1, 2, 4]
}

func main() {
a()
}

Вывод: [0, 1, 2, 3] [0, 1, 2, 4]
Когда у вас недостаточно емкости в слайсе, чтобы добавить новый элемент, Go создает новый массив, в два раза больше предыдущего, и копирует все элементы. Слайсы y и z обе ссылки на этот новый массив.

</details>

### Вопрос 7: Что выведет этот код?

```go
s := "test"
println(s[0]) // 116 (код ASCII для 't')

// Невозможно изменить символ в строке напрямую. Строки в Go неизменяемы.
// s[0] = "R"  // Это вызовет ошибку компиляции

var newS string = "R"
counter := 0
for _, item := range s {
    counter++
    if counter == 1 {
        continue
    }
    newS = strings.Join([]string{newS, string(item)}, "")
}
println(newS) // Rest
```

### Вопрос 8: Что выведет этот код?

```go
taskList := []string{
    "Проснуться",
    "Покушать",
    "Поработать",
}

wakeup := taskList[0:2] // Какой len/cap
work := taskList[2:3]  // Какой len/cap

wakeup = append(wakeup, "Погулять с собакой")

fmt.Println("Wakeup staff: ", wakeup)
fmt.Println("Workstaff:", work)
```

<details>
  <summary>Ответ</summary>
Исходный слайс taskList содержит:
`[Проснуться, Покушать, Поработать]`

Когда вы делаете срез `wakeup := taskList[0:2]`, вы получаете слайс, который содержит:
`[Проснуться, Покушать]`
`len(wakeup) = 2`
`cap(wakeup) = 3` (вместимость включает в себя все элементы оригинального слайса с начального индекса среза до конца, в данном случае это 3 элемента: Проснуться, Покушать и Поработать)

Теперь, когда вы делаете срез `work := taskList[2:3]`, вы получаете слайс, который содержит:
`[Поработать]`
`len(work) = 1`
`cap(work) = 1` (срез начинается с последнего элемента исходного слайса, так что вместимость равна длине)

Формула расчета новой вместимости
cap(new_slice)=cap(original_slice)−start_index_of_new_slice

Когда вы добавляете "Погулять с собакой" в `wakeup` с помощью append, `wakeup` станет:
`[Проснуться, Покушать, Погулять с собакой]`
Так как у `wakeup` оставалась вместимость 1 до достижения максимальной вместимости (которая равна 3), элемент "Погулять с собакой" будет добавлен в тот же участок памяти.
Таким образом, исходный слайс taskList был изменен и теперь выглядит так:
`[Проснуться, Покушать, Погулять с собакой]`

В итоге:

```
Wakeup staff:  [Проснуться Покушать Погулять с собакой]
Workstaff: [Погулять с собакой]
```

</details>

### Вопрос 9: Mysql. DevOps говорит, что в slowlog есть запрос, который выполняется дольше 10 секунд.

### Он отдал вам запрос и вы вызвали explain.

| id  | select_type        | table | partitions | type   | possible_keys                   | key                             | key_len | ref               | rows   | filtered | Extra                    |
| --- | ------------------ | ----- | ---------- | ------ | ------------------------------- | ------------------------------- | ------- | ----------------- | ------ | -------- | ------------------------ |
| 1   | PRIMARY            | mc    | NULL       | ref    | idx_manager_id_client_id_uindex | idx_manager_id_client_id_uindex | 1023    | const             | 1      | 100      | Using where; Using index |
| 1   | PRIMARY            | m     | NULL       | eq_ref | idx_user_id                     | idx_user_id                     | 1022    | bind.mc.client_id | 1      | 100      | Using where              |
| 2   | DEPENDENT SUBQUERY | cdp   | NULL       | index  | idx_client_id                   | idx_client_id                   | 1022    | NULL              | 189480 | 20.61    | Using where              |

Можно ли ускорить этот запрос?
Запрос выбирает клиентов определенного менеджера, у которых указано два этапа сделки

```sql
SELECT m.*
FROM members m
         LEFT JOIN manager_clients mc on m.user_id = mc.client_id
WHERE mc.manager_id = '152734'
  AND m.user_id IN (SELECT client_id
                    FROM client_deal_phases cdp
                    WHERE cdp.phase_id IN (45, 47)
                    GROUP BY client_id
                    HAVING count(client_id) = 2
);
```

<details>
  <summary>Ответ</summary>
Анализ вывода EXPLAIN:

    В таблице mc используется индекс idx_manager_id_client_id_uindex, и только одна запись соответствует критериям фильтрации.
    В таблице m используется индекс idx_user_id, и только одна запись соответствует критериям фильтрации.
    Но главная проблема здесь - это DEPENDENT SUBQUERY для таблицы cdp. Это подзапрос выполняется для каждой строки основного запроса. Для этого запроса используется индекс idx_client_id, и он возвращает 189480 строк, из которых только 20.61% проходят фильтрацию.

Рекомендации по оптимизации:

    Избавьтесь от вложенного подзапроса, используя соединение (JOIN).
    Используйте дополнительный индекс для столбца phase_id в таблице client_deal_phases для ускорения фильтрации.

Оптимизированный запрос:

```sql
SELECT m.*
FROM members m
JOIN manager_clients mc on m.user_id = mc.client_id
JOIN (
    SELECT client_id
    FROM client_deal_phases
    WHERE phase_id IN (45, 47)
    GROUP BY client_id
    HAVING count(client_id) = 2
) cdp ON m.user_id = cdp.client_id
WHERE mc.manager_id = '152734';
```

Здесь мы используем внутренний запрос с группировкой, чтобы выбрать все client_id, которые имеют два этапа сделки, и затем присоединяем этот результат к основному запросу. Это позволит базе данных оптимизировать выполнение запроса, избегая многократного выполнения вложенного подзапроса.

</details>

## Goroutines и Channels

### Вопрос 1: Что выведет следующий код?

## Работа со строками

## Вклад :heart:

Если у вас есть интересные вопросы или вы нашли ошибку, не стесняйтесь создавать PR или Issue. Вместе мы сделаем этот ресурс лучше!

## Лицензия

MIT License. См. LICENSE для деталей.

Удачи! :four_leaf_clover:

```

```
